{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a05887c4-5c9f-4e57-a4dd-9be8f4857dcc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import datatable as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, Input\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "771feba9-1e19-49d9-a2af-d6d3f2e76c8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if 1 == len(physical_devices):\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6788ce30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32e1a564-c83a-4120-a6fa-43189563134c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1b62c0e5-cfbb-4381-b8cf-e756b88e8dd0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('embeddings_100.pkl', 'rb') as file:\n",
    "    weights = pickle.load(file)\n",
    "word2idx = {}\n",
    "with open('word2idx.pkl', 'rb') as file:\n",
    "    word2idx = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "85785e54-a4c9-461b-9267-e16ad77d5e7a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_data(file_path, files_extension, data_percent):\n",
    "    X1, X2, Y = [], [], []\n",
    "    max = 0\n",
    "    \n",
    "    columns_to_drop = [\"C0\", \"puuid\", \"bigger_region\", \"region\", \"tier\", \"champion_rarity\", \"champion_tier\"]\n",
    "    \n",
    "    print('Creating data:')\n",
    "    files = glob.glob(file_path + '/*.' + files_extension)\n",
    "    files = files[:len(files)*data_percent//100]\n",
    "    \n",
    "    for file in tqdm(files):\n",
    "        df = dt.fread(file).to_pandas()\n",
    "        df.drop(columns = columns_to_drop, axis=1, inplace=True)\n",
    "        df.replace('', 'null', inplace=True)\n",
    "        \n",
    "        if pd.unique(df.placement).shape[0] != 8:\n",
    "            continue\n",
    "    \n",
    "        teams = []\n",
    "        for place in range(1, 9): \n",
    "            team = df.where(df[\"placement\"] == place).dropna()\n",
    "            team.drop(columns=[\"placement\"], inplace=True)\n",
    "            team = team.apply(lambda row: ' '.join(row.fillna('').astype(str)), axis=1)\n",
    "            \n",
    "            team_word = ' '.join(team).split()\n",
    "            team_vec = [weights[word2idx[word]-1] if word != 'null' \n",
    "                        else np.zeros(100, dtype=np.float32) for word in team_word ]\n",
    "            team_vec = np.array(team_vec, dtype=np.float32)\n",
    "    \n",
    "            max = team_vec.shape[0] if team_vec.shape[0] > max else max\n",
    "            teams.append(team_vec)\n",
    "    \n",
    "        for team_1 in range(8): \n",
    "            for team_2 in range(8):\n",
    "                if team_1 == team_2:\n",
    "                    continue\n",
    "                X1.append(teams[team_1])\n",
    "                X2.append(teams[team_2])\n",
    "                if team_1 < team_2:\n",
    "                    Y.append(1)\n",
    "                else:\n",
    "                    Y.append(0)\n",
    "                    \n",
    "    print(\"Aligning data:\")\n",
    "    for i in tqdm(range(len(X1))):\n",
    "        to_add = max - X1[i].shape[0]\n",
    "        aaa = np.zeros((to_add, 100), dtype=np.float32)\n",
    "        X1[i] = np.vstack((X1[i], aaa))\n",
    "\n",
    "        to_add = max - X2[i].shape[0]\n",
    "        aaa = np.zeros((to_add, 100))\n",
    "        X2[i] = np.vstack((X2[i], aaa))\n",
    "        \n",
    "    print(\"Converting lists to numpy arrays:\")\n",
    "    X1, X2, Y = np.array(X1), np.array(X2), np.array(Y)\n",
    "\n",
    "    print(\"Success\")\n",
    "    return X1, X2, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7b4fc7c9-b08c-49a2-92c0-67015989d01a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|████████████████████████████████████████████████████████████████████████████████| 841/841 [00:36<00:00, 23.26it/s]\n"
=======
      "100%|████████████████████████████████████████████████████████████████████████████████| 841/841 [00:39<00:00, 21.23it/s]\n"
>>>>>>> 246f79df621c8b8b52b909ee7efe2775ead1bb6a
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|█████████████████████████████████████████████████████████████████████████| 46984/46984 [00:02<00:00, 18178.59it/s]\n"
=======
      "100%|█████████████████████████████████████████████████████████████████████████| 46984/46984 [00:02<00:00, 15663.94it/s]\n"
>>>>>>> 246f79df621c8b8b52b909ee7efe2775ead1bb6a
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting lists to numpy arrays:\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "file_path = '../data_scraping/04.04.2024'\n",
    "files_extension = 'csv'\n",
    "data_percent = 10\n",
    "X1, X2, Y = create_data(file_path, files_extension, data_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "050be7b3-af08-4543-8e70-ae9db7708da2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(91, 100, 1), n_channels=1,\n",
    "                 n_classes=10, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [k for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X1 = np.empty((self.batch_size, *self.dim))\n",
    "        X2 = np.empty((self.batch_size, *self.dim))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X1[i,] = self.list_IDs[ID][0]\n",
    "            X2[i,] = self.list_IDs[ID][1]\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return [X1, X2], y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585c5dbe-1e9e-466f-a987-6f9bee5394ba",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Sieć syjamska"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8d3c034a-c4d4-48ac-8d6c-6ac2203572bc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = tf.reduce_sum(tf.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.sqrt(tf.maximum(sum_square, tf.keras.backend.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b75e14f4-532b-4833-8555-e57c7d590511",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 4500\n"
     ]
    }
   ],
   "source": [
    "data_cut = 46984\n",
    "data_cut = 30000\n",
    "valid_data = int(0.15 * data_cut)\n",
    "print(data_cut, valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "16e6041e-2122-4a55-a581-fa836f3db780",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "valid_X1 = X1[data_cut-valid_data:data_cut:]\n",
    "valid_X2 = X2[data_cut-valid_data:data_cut:]\n",
    "valid_Y = Y [data_cut-valid_data:data_cut:]\n",
    "\n",
    "val_X1 = X1[int((data_cut-valid_data)*0.8):data_cut-valid_data]\n",
    "val_X2 = X2[int((data_cut-valid_data)*0.8):data_cut-valid_data]\n",
    "val_Y = Y[int((data_cut-valid_data)*0.8):data_cut-valid_data]\n",
    "\n",
    "X1 = X1[:int((data_cut-valid_data)*0.8)]\n",
    "X2 = X2[:int((data_cut-valid_data)*0.8)]\n",
    "Y = Y[:int((data_cut-valid_data)*0.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ab910aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5100, 91, 100)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "02152339",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {}\n",
    "labels = {}\n",
    "for x in range(X1.shape[0]):\n",
    "    values[x] = [X1[x], X2[x]]\n",
    "    labels[x] = Y[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "147e88c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = DataGenerator(values, labels, 32, (91, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2027c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_val = {}\n",
    "labels_val = {}\n",
    "for x in range(val_X1.shape[0]):\n",
    "    values_val[x] = [val_X1[x], val_X2[x]]\n",
    "    labels_val[x] = val_Y[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c532c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_val = DataGenerator(values_val, labels_val, 32, (91, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aa4a01c1-57b7-4d9b-ae4f-c556b9f9796f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25500, 91, 100)\n",
      "(4500, 91, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X1.shape)\n",
    "print(valid_X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9731d153-5eb9-422c-a489-bfa9b0281323",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = (X1.shape[1], X1.shape[2], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a1d376d6-8518-4e83-b87a-a43f49ddc090",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Base Network\n",
    "base_network = models.Sequential(name='Base_Network')\n",
    "\n",
    "base_network.add(Input(shape=input_shape))\n",
    "\n",
    "base_network.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', name='Conv2D_1_1'))\n",
    "base_network.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', name='Conv2D_1_2'))\n",
    "base_network.add(layers.BatchNormalization())\n",
    "base_network.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "base_network.add(layers.Conv2D(filters=64, kernel_size=(2, 2), activation='relu', padding='same', name='Conv2D_2_1'))\n",
    "base_network.add(layers.Conv2D(filters=64, kernel_size=(2, 2), activation='relu', padding='same', name='Conv2D_2_2'))\n",
    "base_network.add(layers.BatchNormalization())\n",
    "\n",
    "base_network.add(layers.GlobalMaxPooling2D())\n",
    "\n",
    "base_network.add(layers.Dropout(0.5))\n",
    "base_network.add(layers.Dense(128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3c772bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n",
      "20400\n"
     ]
    }
   ],
   "source": [
    "for _, s in generator:\n",
    "    print(len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "6a0c5deb-5872-417d-99de-adf13b5d4680",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Siamese_Network\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Team 1 (InputLayer)            [(None, 91, 100, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " Team 2 (InputLayer)            [(None, 91, 100, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " Base_Network (Sequential)      (None, 128)          42976       ['Team 1[0][0]',                 \n",
      "                                                                  'Team 2[0][0]']                 \n",
      "                                                                                                  \n",
      " Concatenate (Concatenate)      (None, 256)          0           ['Base_Network[0][0]',           \n",
      "                                                                  'Base_Network[1][0]']           \n",
      "                                                                                                  \n",
      " Output (Dense)                 (None, 1)            257         ['Concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 43,233\n",
      "Trainable params: 43,041\n",
      "Non-trainable params: 192\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Siamese Network\n",
    "input_a = Input(shape=input_shape, name='Team 1')\n",
    "input_b = Input(shape=input_shape, name='Team 2')\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "# distance = layers.Lambda(euclidean_distance, name='Euclidean_Distance')([processed_a, processed_b])\n",
    "# sub = layers.Subtract(name = 'Subtract')([processed_a, processed_b])\n",
    "concat = layers.Concatenate(name='Concatenate')([processed_a, processed_b])\n",
    "\n",
    "output = layers.Dense(1, activation='sigmoid', name='Output')(concat)\n",
    "\n",
    "model_siamese = models.Model(inputs=[input_a, input_b], outputs=output, name='Siamese_Network')\n",
    "\n",
    "# model_siamese.compile(loss=contrastive_loss, optimizer='adam', metrics=[\"accuracy\"])\n",
    "model_siamese.compile(loss='mean_squared_error', optimizer='adamax', metrics=[\"accuracy\", \"mse\"])\n",
    "#model_siamese.compile(loss='binary_crossentropy', optimizer='adamax', metrics=[\"accuracy\"])\n",
    "\n",
    "model_siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "876aa38c-7e27-4039-821d-55f8cfa3a40c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epoch = 1000\n",
    "time = datetime.now().strftime('%Y-%m-%d_%H%M%S')\n",
    "checkpoint_path = f'cp/{time}/{epoch}.h5'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8006bc1e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "637/637 [==============================] - 17s 24ms/step - loss: 0.4437 - accuracy: 0.5150 - mse: 0.4437 - val_loss: 0.2786 - val_accuracy: 0.5989 - val_mse: 0.2786\n",
      "Epoch 2/1000\n",
      "637/637 [==============================] - 16s 25ms/step - loss: 0.3312 - accuracy: 0.5423 - mse: 0.3312 - val_loss: 0.2424 - val_accuracy: 0.5717 - val_mse: 0.2424\n",
      "Epoch 3/1000\n",
      "637/637 [==============================] - 16s 25ms/step - loss: 0.2511 - accuracy: 0.5682 - mse: 0.2511 - val_loss: 0.2570 - val_accuracy: 0.5297 - val_mse: 0.2570\n",
      "Epoch 4/1000\n",
      "637/637 [==============================] - 16s 25ms/step - loss: 0.2370 - accuracy: 0.6063 - mse: 0.2370 - val_loss: 0.2286 - val_accuracy: 0.6226 - val_mse: 0.2286\n",
      "Epoch 5/1000\n",
      "637/637 [==============================] - 16s 25ms/step - loss: 0.2248 - accuracy: 0.6295 - mse: 0.2248 - val_loss: 0.2358 - val_accuracy: 0.6057 - val_mse: 0.2358\n",
      "Epoch 6/1000\n",
      "637/637 [==============================] - 16s 25ms/step - loss: 0.2118 - accuracy: 0.6686 - mse: 0.2118 - val_loss: 0.2378 - val_accuracy: 0.6040 - val_mse: 0.2378\n",
      "Epoch 7/1000\n",
      "637/637 [==============================] - 15s 24ms/step - loss: 0.1976 - accuracy: 0.6976 - mse: 0.1976 - val_loss: 0.2223 - val_accuracy: 0.6317 - val_mse: 0.2223\n",
      "Epoch 8/1000\n",
      "637/637 [==============================] - 15s 24ms/step - loss: 0.1870 - accuracy: 0.7187 - mse: 0.1870 - val_loss: 0.2333 - val_accuracy: 0.6327 - val_mse: 0.2333\n",
      "Epoch 9/1000\n",
      "637/637 [==============================] - 15s 24ms/step - loss: 0.1775 - accuracy: 0.7348 - mse: 0.1775 - val_loss: 0.2285 - val_accuracy: 0.6256 - val_mse: 0.2285\n",
      "Epoch 10/1000\n",
      "637/637 [==============================] - 16s 25ms/step - loss: 0.1684 - accuracy: 0.7509 - mse: 0.1684 - val_loss: 0.2322 - val_accuracy: 0.6417 - val_mse: 0.2322\n",
      "Epoch 11/1000\n",
      "637/637 [==============================] - 16s 25ms/step - loss: 0.1609 - accuracy: 0.7662 - mse: 0.1609 - val_loss: 0.2361 - val_accuracy: 0.6411 - val_mse: 0.2361\n",
      "Epoch 12/1000\n",
      "637/637 [==============================] - 16s 25ms/step - loss: 0.1533 - accuracy: 0.7777 - mse: 0.1533 - val_loss: 0.2367 - val_accuracy: 0.6350 - val_mse: 0.2367\n",
      "Epoch 13/1000\n",
      "637/637 [==============================] - 16s 24ms/step - loss: 0.1492 - accuracy: 0.7851 - mse: 0.1492 - val_loss: 0.2558 - val_accuracy: 0.6419 - val_mse: 0.2558\n",
      "Epoch 14/1000\n",
      "637/637 [==============================] - 16s 24ms/step - loss: 0.1419 - accuracy: 0.7969 - mse: 0.1419 - val_loss: 0.2436 - val_accuracy: 0.6525 - val_mse: 0.2436\n",
      "Epoch 15/1000\n",
      "637/637 [==============================] - 15s 24ms/step - loss: 0.1374 - accuracy: 0.8066 - mse: 0.1374 - val_loss: 0.2481 - val_accuracy: 0.6415 - val_mse: 0.2481\n",
      "Epoch 16/1000\n",
      "637/637 [==============================] - 15s 24ms/step - loss: 0.1354 - accuracy: 0.8069 - mse: 0.1354 - val_loss: 0.2624 - val_accuracy: 0.6338 - val_mse: 0.2624\n",
      "Epoch 17/1000\n",
      "637/637 [==============================] - 16s 24ms/step - loss: 0.1311 - accuracy: 0.8148 - mse: 0.1311 - val_loss: 0.2437 - val_accuracy: 0.6301 - val_mse: 0.2437\n",
      "Epoch 18/1000\n",
      "637/637 [==============================] - 16s 25ms/step - loss: 0.1295 - accuracy: 0.8169 - mse: 0.1295 - val_loss: 0.2477 - val_accuracy: 0.6415 - val_mse: 0.2477\n",
      "Epoch 19/1000\n",
      "637/637 [==============================] - 16s 24ms/step - loss: 0.1264 - accuracy: 0.8253 - mse: 0.1264 - val_loss: 0.2435 - val_accuracy: 0.6452 - val_mse: 0.2435\n",
      "Epoch 20/1000\n",
      "637/637 [==============================] - 16s 25ms/step - loss: 0.1241 - accuracy: 0.8247 - mse: 0.1241 - val_loss: 0.2368 - val_accuracy: 0.6380 - val_mse: 0.2368\n",
      "Epoch 21/1000\n",
      "637/637 [==============================] - 16s 25ms/step - loss: 0.1218 - accuracy: 0.8276 - mse: 0.1218 - val_loss: 0.2579 - val_accuracy: 0.6390 - val_mse: 0.2579\n",
      "Epoch 22/1000\n",
      "637/637 [==============================] - 15s 24ms/step - loss: 0.1196 - accuracy: 0.8308 - mse: 0.1196 - val_loss: 0.2509 - val_accuracy: 0.6327 - val_mse: 0.2509\n",
      "Epoch 23/1000\n",
      "637/637 [==============================] - 15s 24ms/step - loss: 0.1166 - accuracy: 0.8375 - mse: 0.1166 - val_loss: 0.2344 - val_accuracy: 0.6517 - val_mse: 0.2344\n",
      "Epoch 24/1000\n",
      "637/637 [==============================] - 15s 24ms/step - loss: 0.1132 - accuracy: 0.8399 - mse: 0.1132 - val_loss: 0.2491 - val_accuracy: 0.6399 - val_mse: 0.2491\n",
      "Epoch 25/1000\n",
      "637/637 [==============================] - 16s 25ms/step - loss: 0.1101 - accuracy: 0.8479 - mse: 0.1101 - val_loss: 0.2462 - val_accuracy: 0.6478 - val_mse: 0.2462\n",
      "Epoch 26/1000\n",
      "637/637 [==============================] - 16s 25ms/step - loss: 0.1096 - accuracy: 0.8472 - mse: 0.1096 - val_loss: 0.2552 - val_accuracy: 0.6338 - val_mse: 0.2552\n",
      "Epoch 27/1000\n",
      "637/637 [==============================] - 16s 25ms/step - loss: 0.1067 - accuracy: 0.8490 - mse: 0.1067 - val_loss: 0.2547 - val_accuracy: 0.6329 - val_mse: 0.2547\n",
      "Epoch 28/1000\n",
      "637/637 [==============================] - 16s 25ms/step - loss: 0.1058 - accuracy: 0.8539 - mse: 0.1058 - val_loss: 0.2463 - val_accuracy: 0.6533 - val_mse: 0.2463\n",
      "Epoch 29/1000\n",
      "637/637 [==============================] - 16s 24ms/step - loss: 0.1017 - accuracy: 0.8587 - mse: 0.1017 - val_loss: 0.2529 - val_accuracy: 0.6586 - val_mse: 0.2529\n",
      "Epoch 30/1000\n",
      "637/637 [==============================] - 16s 25ms/step - loss: 0.1023 - accuracy: 0.8596 - mse: 0.1023 - val_loss: 0.2572 - val_accuracy: 0.6417 - val_mse: 0.2572\n",
      "Epoch 31/1000\n",
      "637/637 [==============================] - 16s 25ms/step - loss: 0.0997 - accuracy: 0.8630 - mse: 0.0997 - val_loss: 0.2535 - val_accuracy: 0.6452 - val_mse: 0.2535\n",
      "Epoch 32/1000\n",
      "637/637 [==============================] - 16s 24ms/step - loss: 0.0980 - accuracy: 0.8645 - mse: 0.0980 - val_loss: 0.2509 - val_accuracy: 0.6625 - val_mse: 0.2509\n",
      "Epoch 33/1000\n",
      "637/637 [==============================] - 16s 24ms/step - loss: 0.1003 - accuracy: 0.8590 - mse: 0.1003 - val_loss: 0.2483 - val_accuracy: 0.6523 - val_mse: 0.2483\n",
      "Epoch 34/1000\n",
      "637/637 [==============================] - 16s 24ms/step - loss: 0.0967 - accuracy: 0.8664 - mse: 0.0967 - val_loss: 0.2468 - val_accuracy: 0.6543 - val_mse: 0.2468\n",
      "Epoch 35/1000\n",
      "637/637 [==============================] - 16s 25ms/step - loss: 0.0930 - accuracy: 0.8709 - mse: 0.0930 - val_loss: 0.2520 - val_accuracy: 0.6421 - val_mse: 0.2520\n",
      "Epoch 36/1000\n",
      "637/637 [==============================] - 16s 25ms/step - loss: 0.0902 - accuracy: 0.8754 - mse: 0.0902 - val_loss: 0.2564 - val_accuracy: 0.6588 - val_mse: 0.2564\n",
      "Epoch 37/1000\n",
      "637/637 [==============================] - 16s 25ms/step - loss: 0.0924 - accuracy: 0.8736 - mse: 0.0924 - val_loss: 0.2581 - val_accuracy: 0.6529 - val_mse: 0.2581\n",
      "Epoch 38/1000\n",
      "637/637 [==============================] - 15s 24ms/step - loss: 0.0921 - accuracy: 0.8732 - mse: 0.0921 - val_loss: 0.2477 - val_accuracy: 0.6419 - val_mse: 0.2477\n",
      "Epoch 39/1000\n",
      "637/637 [==============================] - 15s 24ms/step - loss: 0.0868 - accuracy: 0.8810 - mse: 0.0868 - val_loss: 0.2537 - val_accuracy: 0.6561 - val_mse: 0.2537\n",
      "Epoch 40/1000\n",
      "637/637 [==============================] - 15s 24ms/step - loss: 0.0861 - accuracy: 0.8807 - mse: 0.0861 - val_loss: 0.2524 - val_accuracy: 0.6572 - val_mse: 0.2524\n",
      "Epoch 41/1000\n",
      "637/637 [==============================] - 15s 24ms/step - loss: 0.0847 - accuracy: 0.8834 - mse: 0.0847 - val_loss: 0.2538 - val_accuracy: 0.6382 - val_mse: 0.2538\n",
      "Epoch 42/1000\n",
      "637/637 [==============================] - 15s 24ms/step - loss: 0.0815 - accuracy: 0.8878 - mse: 0.0815 - val_loss: 0.2528 - val_accuracy: 0.6525 - val_mse: 0.2528\n",
      "Epoch 43/1000\n",
      "637/637 [==============================] - 15s 24ms/step - loss: 0.0807 - accuracy: 0.8896 - mse: 0.0807 - val_loss: 0.2580 - val_accuracy: 0.6519 - val_mse: 0.2580\n",
      "Epoch 44/1000\n",
      "637/637 [==============================] - 16s 25ms/step - loss: 0.0811 - accuracy: 0.8894 - mse: 0.0811 - val_loss: 0.2619 - val_accuracy: 0.6458 - val_mse: 0.2619\n",
      "Epoch 45/1000\n",
      "637/637 [==============================] - 15s 24ms/step - loss: 0.0777 - accuracy: 0.8946 - mse: 0.0777 - val_loss: 0.2556 - val_accuracy: 0.6460 - val_mse: 0.2556\n",
      "Epoch 46/1000\n",
      "210/637 [========>.....................] - ETA: 9s - loss: 0.0753 - accuracy: 0.8967 - mse: 0.0753"
     ]
    }
   ],
   "source": [
    "model_siamese.fit(generator, validation_data=generator_val, \n",
    "                  epochs=epoch, batch_size=32, \n",
    "                  shuffle=True, verbose=True, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a31fb06",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 6ms/step - loss: 1.7567 - accuracy: 0.2638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7566883563995361, 0.26377779245376587]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_siamese.evaluate([valid_X1, valid_X2], valid_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34e21f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 100)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_X1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377f5662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2766a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "predict = model_siamese.predict([valid_X1, valid_X2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "898cea56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.        , -0.9999957 , -0.9999831 , -0.9999827 , -0.9999824 ,\n",
       "       -0.9999389 , -0.9998407 , -0.99956155, -0.9992772 , -0.99912673,\n",
       "       -0.983054  , -0.97993654, -0.9719174 , -0.9224077 , -0.7501689 ,\n",
       "       -0.7060309 , -0.67198   ,  0.07255161,  0.11754357,  0.1895602 ,\n",
       "        0.67168885,  0.72368103,  0.8098381 ,  0.9915367 ,  0.99584883,\n",
       "        0.9996038 ,  0.9999298 ,  0.9999765 ,  0.999987  ,  0.99999475,\n",
       "        0.9999973 ,  0.99999905,  0.9999991 ,  1.        ], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27a83eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[-1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[-1.]\n",
      "[1.]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    print(predict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abffc4a-8af2-4c50-8946-f399b3006d8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_siamese.evaluate([valid_X1, valid_X2], valid_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7e779d-dd97-4676-a6ac-7b1d1862c7f6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4195fe03-4eee-4ffd-a6cb-93ceca7cd2a1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = np.round(model_siamese.predict([valid_X1, valid_X2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f46c878-f2d8-43f4-9080-80fc0bbe966f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f83cc89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "406a641e-67e7-42a7-aecd-0af3d118a51c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predicted_labels = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8cddbb3-4d1d-4179-9107-1ea89cba56ee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.56      0.59      0.57      2252\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.56      0.53      0.55      2248\n",
      "\n",
      "    accuracy                           0.56      4500\n",
      "   macro avg       0.37      0.37      0.37      4500\n",
      "weighted avg       0.56      0.56      0.56      4500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(valid_Y, predicted_labels, labels=[-1, 1])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Real')\n",
    "plt.title('CM')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(valid_Y, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b9fb8bd-d389-4238-a06f-07e4dad9bb60",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37d8e5f3-3ec0-404b-af82-27923151d241",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model(r'cp/2024-05-23_183449/1000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5900ce44-ebe0-4980-8afe-55ee5ac94e1b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Siamese_Network\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Team 1 (InputLayer)            [(None, 91, 100, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " Team 2 (InputLayer)            [(None, 91, 100, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " Base_Network (Sequential)      (None, 128)          4334304     ['Team 1[0][0]',                 \n",
      "                                                                  'Team 2[0][0]']                 \n",
      "                                                                                                  \n",
      " Concatenate (Concatenate)      (None, 256)          0           ['Base_Network[0][0]',           \n",
      "                                                                  'Base_Network[1][0]']           \n",
      "                                                                                                  \n",
      " Output (Dense)                 (None, 1)            257         ['Concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,334,561\n",
      "Trainable params: 4,334,369\n",
      "Non-trainable params: 192\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "# Siamese Network\n",
    "input_a = Input(shape=input_shape, name='Team 1')\n",
    "input_b = Input(shape=input_shape, name='Team 2')\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "# distance = layers.Lambda(euclidean_distance, name='Euclidean_Distance')([processed_a, processed_b])\n",
    "# sub = layers.Subtract(name = 'Subtract')([processed_a, processed_b])\n",
    "concat = layers.Concatenate(name='Concatenate')([processed_a, processed_b])\n",
    "\n",
    "output = layers.Dense(1, activation='sigmoid', name='Output')(concat)\n",
    "\n",
    "model_siamese = models.Model(inputs=[input_a, input_b], outputs=output, name='Siamese_Network')\n",
    "\n",
    "# model_siamese.compile(loss=contrastive_loss, optimizer='adam', metrics=[\"accuracy\"])\n",
    "model_siamese.compile(loss='mean_squared_error', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "model_siamese.summary()"
=======
    "model.summary()"
>>>>>>> 246f79df621c8b8b52b909ee7efe2775ead1bb6a
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9d8f394-fd5f-44a1-9e8d-7547d2415b31",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "144/144 [==============================] - 36s 198ms/step - loss: 0.4931 - accuracy: 0.5064 - val_loss: 0.4595 - val_accuracy: 0.5369\n",
      "Epoch 2/1000\n",
      "144/144 [==============================] - 27s 189ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4980 - val_accuracy: 0.5020\n",
      "Epoch 3/1000\n",
      "144/144 [==============================] - 28s 192ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 4/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 5/1000\n",
      "144/144 [==============================] - 29s 198ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 6/1000\n",
      "144/144 [==============================] - 29s 202ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 7/1000\n",
      "144/144 [==============================] - 30s 205ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 8/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 9/1000\n",
      "144/144 [==============================] - 30s 209ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 10/1000\n",
      "144/144 [==============================] - 30s 212ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 11/1000\n",
      "144/144 [==============================] - 31s 212ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 12/1000\n",
      "144/144 [==============================] - 30s 211ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 13/1000\n",
      "144/144 [==============================] - 30s 211ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 14/1000\n",
      "144/144 [==============================] - 30s 210ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 15/1000\n",
      "144/144 [==============================] - 30s 212ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 16/1000\n",
      "144/144 [==============================] - 31s 213ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 17/1000\n",
      "144/144 [==============================] - 31s 213ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 18/1000\n",
      "144/144 [==============================] - 31s 214ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 19/1000\n",
      "144/144 [==============================] - 31s 212ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 20/1000\n",
      "144/144 [==============================] - 31s 214ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 21/1000\n",
      "144/144 [==============================] - 31s 214ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 22/1000\n",
      "144/144 [==============================] - 31s 213ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 23/1000\n",
      "144/144 [==============================] - 31s 214ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 24/1000\n",
      "144/144 [==============================] - 31s 215ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 25/1000\n",
      "144/144 [==============================] - 31s 215ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 26/1000\n",
      "144/144 [==============================] - 31s 217ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 27/1000\n",
      "144/144 [==============================] - 31s 215ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 28/1000\n",
      "144/144 [==============================] - 32s 220ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 29/1000\n",
      "144/144 [==============================] - 32s 223ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 30/1000\n",
      "144/144 [==============================] - 32s 221ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 31/1000\n",
      "144/144 [==============================] - 32s 221ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 32/1000\n",
      "144/144 [==============================] - 32s 222ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 33/1000\n",
      "144/144 [==============================] - 32s 224ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 34/1000\n",
      "144/144 [==============================] - 32s 225ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 35/1000\n",
      "144/144 [==============================] - 32s 225ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 36/1000\n",
      "144/144 [==============================] - 32s 226ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 37/1000\n",
      "144/144 [==============================] - 32s 225ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 38/1000\n",
      "144/144 [==============================] - 33s 227ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 39/1000\n",
      "144/144 [==============================] - 32s 225ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 40/1000\n",
      "144/144 [==============================] - 33s 227ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 41/1000\n",
      "144/144 [==============================] - 33s 227ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 42/1000\n",
      "144/144 [==============================] - 33s 227ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 43/1000\n",
      "144/144 [==============================] - 32s 226ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 44/1000\n",
      "144/144 [==============================] - 33s 227ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 45/1000\n",
      "144/144 [==============================] - 33s 227ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 46/1000\n",
      "144/144 [==============================] - 33s 227ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 47/1000\n",
      "144/144 [==============================] - 33s 226ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 48/1000\n",
      "144/144 [==============================] - 33s 227ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 49/1000\n",
      "144/144 [==============================] - 33s 227ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 50/1000\n",
      "144/144 [==============================] - 33s 228ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 51/1000\n",
      "144/144 [==============================] - 33s 228ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 52/1000\n",
      "144/144 [==============================] - 33s 229ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 53/1000\n",
      "144/144 [==============================] - 33s 229ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 54/1000\n",
      "144/144 [==============================] - 33s 229ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 55/1000\n",
      "144/144 [==============================] - 33s 228ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 56/1000\n",
      "144/144 [==============================] - 33s 228ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 57/1000\n",
      "144/144 [==============================] - 33s 229ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 58/1000\n",
      "144/144 [==============================] - 33s 229ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 59/1000\n",
      "144/144 [==============================] - 33s 228ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 60/1000\n",
      "144/144 [==============================] - 33s 229ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 61/1000\n",
      "144/144 [==============================] - 33s 229ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 62/1000\n",
      "144/144 [==============================] - 33s 228ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 63/1000\n",
      "144/144 [==============================] - 33s 228ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 64/1000\n",
      "144/144 [==============================] - 33s 230ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 65/1000\n",
      "144/144 [==============================] - 33s 230ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 66/1000\n",
      "144/144 [==============================] - 33s 230ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 67/1000\n",
      "144/144 [==============================] - 33s 233ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 68/1000\n",
      "144/144 [==============================] - 34s 235ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 69/1000\n",
      "144/144 [==============================] - 34s 235ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 70/1000\n",
      "144/144 [==============================] - 34s 236ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 71/1000\n",
      "144/144 [==============================] - 34s 235ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 72/1000\n",
      "144/144 [==============================] - 34s 235ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 73/1000\n",
      "144/144 [==============================] - 34s 236ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 74/1000\n",
      "144/144 [==============================] - 34s 237ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 75/1000\n",
      "144/144 [==============================] - 35s 244ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 76/1000\n",
      "144/144 [==============================] - 35s 247ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 77/1000\n",
      "144/144 [==============================] - 35s 247ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 78/1000\n",
      "144/144 [==============================] - 35s 246ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 79/1000\n",
      "144/144 [==============================] - 35s 246ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 80/1000\n",
      "144/144 [==============================] - 35s 246ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 81/1000\n",
      "144/144 [==============================] - 36s 247ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 82/1000\n",
      "144/144 [==============================] - 35s 247ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 83/1000\n",
      "144/144 [==============================] - 36s 247ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 84/1000\n",
      "144/144 [==============================] - 36s 247ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 85/1000\n",
      "144/144 [==============================] - 35s 246ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 86/1000\n",
      "144/144 [==============================] - 35s 240ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 87/1000\n",
      "144/144 [==============================] - 35s 242ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 88/1000\n",
      "144/144 [==============================] - 35s 242ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 89/1000\n",
      "144/144 [==============================] - 34s 235ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 90/1000\n",
      "144/144 [==============================] - 33s 233ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 91/1000\n",
      "144/144 [==============================] - 33s 232ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 92/1000\n",
      "144/144 [==============================] - 33s 231ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 93/1000\n",
      "144/144 [==============================] - 33s 231ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 94/1000\n",
      "144/144 [==============================] - 33s 229ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 95/1000\n",
      "144/144 [==============================] - 33s 228ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 96/1000\n",
      "144/144 [==============================] - 33s 228ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 97/1000\n",
      "144/144 [==============================] - 33s 229ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 98/1000\n",
      "144/144 [==============================] - 33s 228ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 99/1000\n",
      "144/144 [==============================] - 33s 228ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 100/1000\n",
      "144/144 [==============================] - 33s 227ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 101/1000\n",
      "144/144 [==============================] - 33s 227ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 102/1000\n",
      "144/144 [==============================] - 33s 227ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 103/1000\n",
      "144/144 [==============================] - 33s 228ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 104/1000\n",
      "144/144 [==============================] - 33s 229ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 105/1000\n",
      "144/144 [==============================] - 33s 229ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 106/1000\n",
      "144/144 [==============================] - 33s 228ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 107/1000\n",
      "144/144 [==============================] - 33s 228ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 108/1000\n",
      "144/144 [==============================] - 33s 227ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 109/1000\n",
      "144/144 [==============================] - 33s 227ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 110/1000\n",
      "144/144 [==============================] - 32s 226ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 111/1000\n",
      "144/144 [==============================] - 32s 225ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 112/1000\n",
      "144/144 [==============================] - 32s 225ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 113/1000\n",
      "144/144 [==============================] - 33s 226ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 114/1000\n",
      "144/144 [==============================] - 32s 225ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 115/1000\n",
      "144/144 [==============================] - 32s 224ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 116/1000\n",
      "144/144 [==============================] - 32s 223ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 117/1000\n",
      "144/144 [==============================] - 32s 223ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 118/1000\n",
      "144/144 [==============================] - 32s 223ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 119/1000\n",
      "144/144 [==============================] - 32s 222ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 120/1000\n",
      "144/144 [==============================] - 32s 223ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 121/1000\n",
      "144/144 [==============================] - 32s 223ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 122/1000\n",
      "144/144 [==============================] - 32s 223ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 123/1000\n",
      "144/144 [==============================] - 32s 225ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 124/1000\n",
      "144/144 [==============================] - 32s 226ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 125/1000\n",
      "144/144 [==============================] - 32s 226ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 126/1000\n",
      "144/144 [==============================] - 32s 225ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 127/1000\n",
      "144/144 [==============================] - 32s 226ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 128/1000\n",
      "144/144 [==============================] - 33s 226ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 129/1000\n",
      "144/144 [==============================] - 33s 227ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 130/1000\n",
      "144/144 [==============================] - 33s 227ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 131/1000\n",
      "144/144 [==============================] - 32s 226ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 132/1000\n",
      "144/144 [==============================] - 32s 226ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 133/1000\n",
      "144/144 [==============================] - 32s 225ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 134/1000\n",
      "144/144 [==============================] - 32s 225ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 135/1000\n",
      "144/144 [==============================] - 32s 224ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 136/1000\n",
      "144/144 [==============================] - 32s 225ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 137/1000\n",
      "144/144 [==============================] - 32s 224ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 138/1000\n",
      "144/144 [==============================] - 32s 224ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 139/1000\n",
      "144/144 [==============================] - 32s 223ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 140/1000\n",
      "144/144 [==============================] - 32s 224ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 141/1000\n",
      "144/144 [==============================] - 32s 222ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 142/1000\n",
      "144/144 [==============================] - 32s 220ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 143/1000\n",
      "144/144 [==============================] - 31s 216ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 144/1000\n",
      "144/144 [==============================] - 31s 215ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 145/1000\n",
      "144/144 [==============================] - 31s 213ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 146/1000\n",
      "144/144 [==============================] - 30s 211ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 147/1000\n",
      "144/144 [==============================] - 30s 212ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 148/1000\n",
      "144/144 [==============================] - 30s 212ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 149/1000\n",
      "144/144 [==============================] - 30s 211ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 150/1000\n",
      "144/144 [==============================] - 30s 209ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 151/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 152/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 153/1000\n",
      "144/144 [==============================] - 30s 208ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 154/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 155/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 156/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 157/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 158/1000\n",
      "144/144 [==============================] - 30s 206ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 159/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 160/1000\n",
      "144/144 [==============================] - 30s 206ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 161/1000\n",
      "144/144 [==============================] - 30s 206ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 162/1000\n",
      "144/144 [==============================] - 30s 205ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 163/1000\n",
      "144/144 [==============================] - 29s 205ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 164/1000\n",
      "144/144 [==============================] - 29s 204ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 165/1000\n",
      "144/144 [==============================] - 29s 204ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 166/1000\n",
      "144/144 [==============================] - 29s 204ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 167/1000\n",
      "144/144 [==============================] - 29s 205ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 168/1000\n",
      "144/144 [==============================] - 29s 204ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 169/1000\n",
      "144/144 [==============================] - 29s 204ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 170/1000\n",
      "144/144 [==============================] - 29s 203ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 171/1000\n",
      "144/144 [==============================] - 29s 202ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 172/1000\n",
      "144/144 [==============================] - 29s 202ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 173/1000\n",
      "144/144 [==============================] - 29s 201ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 174/1000\n",
      "144/144 [==============================] - 29s 201ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 175/1000\n",
      "144/144 [==============================] - 29s 201ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 176/1000\n",
      "144/144 [==============================] - 29s 201ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 177/1000\n",
      "144/144 [==============================] - 29s 202ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 178/1000\n",
      "144/144 [==============================] - 29s 200ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 179/1000\n",
      "144/144 [==============================] - 29s 200ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 180/1000\n",
      "144/144 [==============================] - 29s 200ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 181/1000\n",
      "144/144 [==============================] - 29s 198ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 182/1000\n",
      "144/144 [==============================] - 29s 200ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 183/1000\n",
      "144/144 [==============================] - 29s 199ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 184/1000\n",
      "144/144 [==============================] - 29s 200ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 185/1000\n",
      "144/144 [==============================] - 29s 199ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 186/1000\n",
      "144/144 [==============================] - 28s 198ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 187/1000\n",
      "144/144 [==============================] - 29s 199ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 188/1000\n",
      "144/144 [==============================] - 28s 198ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 189/1000\n",
      "144/144 [==============================] - 28s 197ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 190/1000\n",
      "144/144 [==============================] - 28s 197ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 191/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 192/1000\n",
      "144/144 [==============================] - 28s 197ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 193/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 194/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 195/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 196/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 197/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 198/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 199/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 200/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 201/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 202/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 203/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 204/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 205/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 206/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 207/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 208/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 209/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 210/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 211/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 212/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 213/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 214/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 215/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 216/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 217/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 218/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 219/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 220/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 221/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 222/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 223/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 224/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 225/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 226/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 227/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 228/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 229/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 230/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 231/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 232/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 233/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 234/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 235/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 236/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 237/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 238/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 239/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 240/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 241/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 242/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 243/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 244/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 245/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 246/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 247/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 248/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 249/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 250/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 251/1000\n",
      "144/144 [==============================] - 28s 192ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 252/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 253/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 254/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 255/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 256/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 257/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 258/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 259/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 260/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 261/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 262/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 263/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 264/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 265/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 266/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 267/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 268/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 269/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 270/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 271/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 272/1000\n",
      "144/144 [==============================] - 28s 197ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 273/1000\n",
      "144/144 [==============================] - 29s 199ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 274/1000\n",
      "144/144 [==============================] - 28s 197ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 275/1000\n",
      "144/144 [==============================] - 28s 197ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 276/1000\n",
      "144/144 [==============================] - 28s 197ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 277/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 278/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 279/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 280/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 281/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 282/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 283/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 284/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 285/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 286/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 287/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 288/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 289/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 290/1000\n",
      "144/144 [==============================] - 28s 197ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 291/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 292/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 293/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 294/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 295/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 296/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 297/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 298/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 299/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 300/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 301/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 302/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 303/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 304/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 305/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 306/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 307/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 308/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 309/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 310/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 311/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 312/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 313/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 314/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 315/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 316/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 317/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 318/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 319/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 320/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 321/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 322/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 323/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 324/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 325/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 326/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 327/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 328/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 329/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 330/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 331/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 332/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 333/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 334/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 335/1000\n",
      "144/144 [==============================] - 28s 192ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 336/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 337/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 338/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 339/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 340/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 341/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 342/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 343/1000\n",
      "144/144 [==============================] - 28s 194ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 344/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 345/1000\n",
      "144/144 [==============================] - 28s 192ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 346/1000\n",
      "144/144 [==============================] - 28s 192ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 347/1000\n",
      "144/144 [==============================] - 28s 192ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 348/1000\n",
      "144/144 [==============================] - 28s 192ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 349/1000\n",
      "144/144 [==============================] - 28s 192ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 350/1000\n",
      "144/144 [==============================] - 28s 192ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 351/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 352/1000\n",
      "144/144 [==============================] - 28s 192ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 353/1000\n",
      "144/144 [==============================] - 28s 192ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 354/1000\n",
      "144/144 [==============================] - 28s 192ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 355/1000\n",
      "144/144 [==============================] - 28s 191ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 356/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 357/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 358/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 359/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 360/1000\n",
      "144/144 [==============================] - 28s 192ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 361/1000\n",
      "144/144 [==============================] - 28s 192ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 362/1000\n",
      "144/144 [==============================] - 28s 192ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 363/1000\n",
      "144/144 [==============================] - 28s 193ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 364/1000\n",
      "144/144 [==============================] - 28s 192ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 365/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 366/1000\n",
      "144/144 [==============================] - 28s 197ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 367/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 368/1000\n",
      "144/144 [==============================] - 28s 197ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 369/1000\n",
      "144/144 [==============================] - 28s 196ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 370/1000\n",
      "144/144 [==============================] - 28s 195ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 371/1000\n",
      "144/144 [==============================] - 29s 199ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 372/1000\n",
      "144/144 [==============================] - 29s 201ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 373/1000\n",
      "144/144 [==============================] - 29s 202ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 374/1000\n",
      "144/144 [==============================] - 29s 201ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 375/1000\n",
      "144/144 [==============================] - 29s 202ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 376/1000\n",
      "144/144 [==============================] - 29s 203ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 377/1000\n",
      "144/144 [==============================] - 29s 204ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 378/1000\n",
      "144/144 [==============================] - 29s 204ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 379/1000\n",
      "144/144 [==============================] - 29s 204ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 380/1000\n",
      "144/144 [==============================] - 29s 203ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 381/1000\n",
      "144/144 [==============================] - 29s 204ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 382/1000\n",
      "144/144 [==============================] - 29s 203ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 383/1000\n",
      "144/144 [==============================] - 29s 204ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 384/1000\n",
      "144/144 [==============================] - 30s 206ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 385/1000\n",
      "144/144 [==============================] - 30s 206ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 386/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 387/1000\n",
      "144/144 [==============================] - 30s 206ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 388/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 389/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 390/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 391/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 392/1000\n",
      "144/144 [==============================] - 30s 206ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 393/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 394/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 395/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 396/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 397/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 398/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 399/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 400/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 401/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 402/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 403/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 404/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 405/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 406/1000\n",
      "144/144 [==============================] - 30s 207ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 407/1000\n",
      "144/144 [==============================] - 30s 208ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 408/1000\n",
      "144/144 [==============================] - 30s 209ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 409/1000\n",
      "144/144 [==============================] - 30s 208ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 410/1000\n",
      "144/144 [==============================] - 30s 208ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 411/1000\n",
      "144/144 [==============================] - 30s 209ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 412/1000\n",
      "144/144 [==============================] - 30s 210ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 413/1000\n",
      "144/144 [==============================] - 30s 210ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 414/1000\n",
      "144/144 [==============================] - 31s 213ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 415/1000\n",
      "144/144 [==============================] - 30s 212ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 416/1000\n",
      "144/144 [==============================] - 30s 211ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 417/1000\n",
      "144/144 [==============================] - 30s 210ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 418/1000\n",
      "144/144 [==============================] - 30s 210ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 419/1000\n",
      "144/144 [==============================] - 30s 209ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 420/1000\n",
      "144/144 [==============================] - 30s 209ms/step - loss: 0.4998 - accuracy: 0.5002 - val_loss: 0.4988 - val_accuracy: 0.5012\n",
      "Epoch 421/1000\n",
      " 62/144 [===========>..................] - ETA: 16s - loss: 0.5009 - accuracy: 0.4991"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
=======
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x142870433d0>,\n",
       " <keras.engine.input_layer.InputLayer at 0x14287043250>,\n",
       " <keras.engine.sequential.Sequential at 0x142870434f0>,\n",
       " <keras.layers.merging.concatenate.Concatenate at 0x14287063490>,\n",
       " <keras.layers.core.dense.Dense at 0x14287041480>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
>>>>>>> 246f79df621c8b8b52b909ee7efe2775ead1bb6a
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "7abffc4a-8af2-4c50-8946-f399b3006d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_siamese.evaluate([valid_X1, valid_X2], valid_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4195fe03-4eee-4ffd-a6cb-93ceca7cd2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.round(model_siamese.predict([valid_X1, valid_X2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f46c878-f2d8-43f4-9080-80fc0bbe966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406a641e-67e7-42a7-aecd-0af3d118a51c",
   "metadata": {},
=======
   "execution_count": 42,
   "id": "eac7d81d-66e2-4e96-88ee-73d918c3b282",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> 246f79df621c8b8b52b909ee7efe2775ead1bb6a
   "outputs": [],
   "source": [
    "# Provided two tensors t1 and t2\n",
    "# Euclidean distance = sqrt(sum(square(t1-t2)))\n",
    "def euclidean_distance(vects):\n",
    "    \"\"\"Find the Euclidean distance between two vectors.\n",
    "\n",
    "    Arguments:\n",
    "        vects: List containing two tensors of same length.\n",
    "\n",
    "    Returns:\n",
    "        Tensor containing euclidean distance\n",
    "        (as floating point value) between vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = vects\n",
    "    sum_square = ops.sum(ops.square(x - y), axis=1, keepdims=True)\n",
    "    return ops.sqrt(ops.maximum(sum_square, keras.backend.epsilon()))\n",
    "\n",
    "\n",
    "input = keras.layers.Input((28, 28, 1))\n",
    "x = keras.layers.BatchNormalization()(input)\n",
    "x = keras.layers.Conv2D(4, (5, 5), activation=\"tanh\")(x)\n",
    "x = keras.layers.AveragePooling2D(pool_size=(2, 2))(x)\n",
    "x = keras.layers.Conv2D(16, (5, 5), activation=\"tanh\")(x)\n",
    "x = keras.layers.AveragePooling2D(pool_size=(2, 2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(10, activation=\"tanh\")(x)\n",
    "embedding_network = keras.Model(input, x)\n",
    "\n",
    "\n",
    "input_1 = keras.layers.Input((28, 28, 1))\n",
    "input_2 = keras.layers.Input((28, 28, 1))\n",
    "\n",
    "# As mentioned above, Siamese Network share weights between\n",
    "# tower networks (sister networks). To allow this, we will use\n",
    "# same embedding network for both tower networks.\n",
    "tower_1 = embedding_network(input_1)\n",
    "tower_2 = embedding_network(input_2)\n",
    "\n",
    "merge_layer = layers.Concatenate(name='Concatenate')([tower_1, tower_2])\n",
    "normal_layer = keras.layers.BatchNormalization()(merge_layer)\n",
    "output_layer = keras.layers.Dense(1, activation=\"sigmoid\")(normal_layer)\n",
    "siamese = keras.Model(inputs=[input_1, input_2], outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "e8cddbb3-4d1d-4179-9107-1ea89cba56ee",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 43,
   "id": "6bc6ef9b-b859-4623-9b2d-d9ab753c4d42",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "569d84ed-d87a-4109-9f2a-097ae059f0a3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " model_2 (Functional)           (None, 10)           5318        ['input_10[0][0]',               \n",
      "                                                                  'input_11[0][0]']               \n",
      "                                                                                                  \n",
      " Concatenate (Concatenate)      (None, 20)           0           ['model_2[0][0]',                \n",
      "                                                                  'model_2[1][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 20)          80          ['Concatenate[0][0]']            \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            21          ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,419\n",
      "Trainable params: 4,865\n",
      "Non-trainable params: 554\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
>>>>>>> 246f79df621c8b8b52b909ee7efe2775ead1bb6a
   "source": [
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc458b87-94f0-4c8e-9295-6b07c23c88d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
